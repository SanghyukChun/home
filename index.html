<!doctype html>
<html lang="en">
    <head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-42711199-4"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-42711199-4');
        </script>
        <!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <!-- Bootstrap CSS -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link href="./assets/css/common.css" rel="stylesheet">
        <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
        <link rel="icon" type="image/png" href="favicon.png">

        <!-- Roboto -->
        <link rel="preconnect" href="https://fonts.gstatic.com">
        <link href="https://fonts.googleapis.com/css2?family=Roboto&display=swap" rel="stylesheet">


        <title>Sanghyuk Chun - NAVER AI Lab</title>
    </head>
    <body>
        <div class="container-wrapper">
            <div class="container text-justify">
                <div class="mt-5 mb-3">
                    <div class="row profile_header">
                        <div class="col-md-2 d-none d-lg-block d-xl-block">
                            <img src="assets/img/profile2.png" width="100%" max-width="250px" alt="profile" class="rounded-circle shadow-lg">
                        </div>
                        <div class="col-md-10">
                            <h1>Sanghyuk Chun</h1>
                            <ul class="list-unstyled">
                                <li>Lead Research Scientist</li>
                                <li>NAVER AI Lab</li>
                                <li>sanghyuk.chun [at] gmail.com</li>
                                <li><a href="https://scholar.google.co.kr/citations?user=4_uj0xcAAAAJ">Google Scholar</a> | <a href="https://www.semanticscholar.org/author/Sanghyuk-Chun/2647582">Semantic Scholar</a> | <a href="https://github.com/SanghyukChun">Github</a> | <a href="https://twitter.com/SanghyukChun">Twitter</a> | <a href="media/CV_Sanghyuk_Chun_Public_23Jul21.pdf">CV</a> (as of July 23rd, 2021)</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <hr>
                <div class="mb-4">
                    <p>I'm a lead research scientist at <a href="https://naver-career.gitbook.io/en/teams/clova-cic">NAVER AI Lab</a>, working on machine learning and its applications. In particular, my research interests focus on bridging the gap between two gigantic topics: reliable machine learning tasks (<em>e.g.</em>, robustness <sup>[C3, C9, C10, W1, W3, A5]</sup>, de-biasing or domain generalization <sup>[C6, C15, A5, A6]</sup>, uncertainty estimation <sup>[C11, A3]</sup>, explainability <sup>[C5, C11, A2, A4, W2]</sup>, and fair evaluation <sup>[C5, C11]</sup>) and learning with limited annotations (<em>e.g.</em>, multi-modal learning <sup>[C11]</sup>, weakly-supervised learning <sup>[C2, C3, C4, C5, C7, C8, C12, W2, W4, W5, W6, A2, A4]</sup>, and self-supervised learning). I have contributed large-scale machine learning algorithms <sup>[C3, C9, C10, C13, WO1, A7]</sup> in NAVER AI Lab as well. Prior to working at NAVER, I worked as a research engineer at the advanced recommendation team (ART) in <a href="https://www.kakaocorp.com/">Kakao</a> from 2016 to 2018.</p>
                    <p class="mb-0">I received a master's degree in Electrical Engineering from Korea Advanced Institute of Science and Technology (KAIST) in 2016. During the master's degree, I researched on <a href="http://library.kaist.ac.kr/thesis02/2016/2016M020143583_S1.pdf">a scalable algorithm for robust subspace clustering</a> (the algorithm is based on robust PCA and k-means clustering). Before my master's study, I worked at <a href="http://i-um.com/">IUM-SOCIUS</a> in 2012 as a software engineering internship. I also did a research internship at <a href="http://www.ndsl.kaist.edu/">Networked and Distributed Computing System Lab</a> in KAIST and <a href="https://www.naverlabs.com/">NAVER Labs</a> during summer 2013 and fall 2015, respectively.</p>
                </div>
                <hr>
                <div class="mb-4">
                    <p class="font-weight-bold font-italic">NAVER AI Lab is looking for motivated research internship students / regular research scientists (topic: real-world biases, uncertainty estimation, robustness, causality, explainability, large-scale learning, self-supervised learning, multi-modal learning, ...). Our mission is to perform impactful long-term AI research to make AI more beneficial and contribute to the AI community. We, therefore, expect very strong publication records for the applicants. See a more detailed job description <a href="https://naver-career.gitbook.io/en/positions/ai-ml">here</a>. If you are interested in joining our group, please send an email to me (or <tt>naverai at navercorp.com</tt>) with your academic CV and desired topics.</p>
                    <p class="mb-0 font-weight-bold font-italic">If you are interested in the internship position, you have to aware that we expect at least 6-month internship period and we are not hiring undergratuate students (or students who don't have enough publication records). The location will be Seoul, Korea <a href="https://goo.gl/maps/NNn59S8KZsxgcoLC6">[Google map]</a>, but a remote internship program can be considered depending on the situation. Lastly, if you are not a Korean citizen, the whole hiring process could be delayed due to the VISA process.</p>
                </div>
                <hr>
                <h3 id="news">News</h3>
                <div class="mb-5">
                    <ul class="pl15 mb-0">
                        <li>11/2021 : Giving a talk at UNIST (topic: Limits and Challenges in Deep Learning Optimizers) <a href="https://docs.google.com/presentation/d/1NNftqS6BcCPd52tv8gWEjB34retYhP0FToOFBd9ewkQ/edit">[slide]</a></li>
                        <li>_9/2021 : 2 papers <sup><a href="#swad-domain-generalization-by-seeking-flat-minima">[SWAD]</a></sup> <sup><a href="#neural-hybrid-automata-learning-dynamics-with-multiple-modes-and">[NHA]</a></sup> are accepted at NeurIPS 2021.</li>
                        <li>_8/2021: Reaching a research milestone of 1,000 citations at <a href="https://scholar.google.co.kr/citations?user=4_uj0xcAAAAJ">Google Scholar</a> and <a href="https://www.semanticscholar.org/author/Sanghyuk-Chun/2647582">Semantic Scholar</a>!</li>
                        <li>_7/2021 : Co-organizing the NeurIPS Workshop on ImageNet: Past, Present, and Future! <a href="https://sites.google.com/view/imagenet-workshop/home">[webpage]</a></li>
                        <li>_7/2021 : 2 papers <sup><a href="#multiple-heads-are-better-than-one-few-shot-font-generation-with-1">[MX-Font]</a></sup> <sup><a href="#rethinking-spatial-dimensions-of-vision-transformers">[PiT]</a></sup> are accepted at ICCV 2021.</li>
                        <li>_7/2021 : Giving a talk at Computer Vision Centre (CVC), UAB (topic: PCME and AdamP) <a href="http://www.cvc.uab.es/?p=7778">[info]</a> <a href="https://docs.google.com/presentation/d/1dGQUqud3iMld-UgMMlRQuqA7JhzndMfzFoKaFAwZ58I/edit?usp=sharing">[slide]</a></li>
                        <li>_6/2021 : Giving a talk at KSIAM 2021 (topic: AdamP). <a href="https://docs.google.com/presentation/d/1s9zgQ22WFnhEj6POL_0ecrTiED__qmL9XgL0Nv3zNP4/edit?usp=sharing">[slide]</a></li>
                        <li>_6/2021 : Giving a talk at Seoul National University (topic: few-shot font generation) .<a href="https://docs.google.com/presentation/d/13WoYS9r9C751s3nZ2yF5WdestRXh3V7LFQDOJyCrt9s/edit?usp=sharing">[slide]</a></li>
                        <li>_5/2021 : Receiving <strong><span class="text-danger">an outstanding reviewer award</span></strong> at CVPR 2021.</li>
                        <li>_4/2021 : 1 paper <sup><a href="#few-shot-font-generation-with-localized-style-representations-an">[LF-Font]</a></sup> is accepted at CVPR 2021 workshop (also appeared at AAAI).</li>
                        <li>_3/2021 : 2 papers <sup><a href="#probabilistic-embeddings-for-cross-modal-retrieval">[PCME]</a></sup> <sup><a href="#re-labeling-imagenet-from-single-to-multi-labels-from-global-to">[ReLabel]</a></sup> are accepted at CVPR 2021.</li>
                        <li>_1/2021 : 1 paper <sup><a href="#adamp-slowing-down-the-slowdown-for-momentum-optimizers-on-scale">[AdamP]</a></sup> is accepted at ICLR 2021.</li>
                    </ul>
                    <details>
                    <summary>See older news</summary>
                    <ul class="pl15 mb-0"></ul>
                        <li>_7/2020 : 1 paper <sup><a href="#few-shot-compositional-font-generation-with-dual-memory">[DM-Font]</a></sup> is accepted at ECCV 2020.</li>
                        <li>_6/2020 : Receiving <strong><span class="text-danger">the best paper runner-up award</span></strong> at AICCW CVPR 2020.</li>
                        <li>_6/2020 : Receiving <strong><span class="text-danger">an outstanding reviewer award</span></strong> at CVPR 2020.</li>
                        <li>_6/2020 : Giving a talk at CVPR 2020 NAVER interative session.</li>
                        <li>_6/2020 : 1 paper <sup><a href="#learning-de-biased-representations-with-biased-representations">[ReBias]</a></sup> is accepted at ICML 2020.</li>
                        <li>_4/2020 : 1 paper <sup><a href="#toward-high-quality-few-shot-font-generation-with-dual-memory">[DM-Font short]</a></sup> is accepted at CVPR 2020 workshop.</li>
                        <li>_2/2020 : 1 paper <sup><a href="#evaluating-weakly-supervised-object-localization-methods-right">[wsoleval]</a></sup> is accepted at CVPR 2020.</li>
                        <li>_1/2020 : 1 paper <sup><a href="#data-driven-harmonic-filters-for-audio-representation-learning">[HCNN]</a></sup> is accepted at ICASSP 2020.</li>
                        <li>10/2019 : 1 paper <sup><a href="#automatic-music-tagging-with-harmonic-cnn">[HCNN short]</a></sup> is accpeted at ISMIR late break demo.</li>
                        <li>10/2019 : Working at Naver Labs Europe as a visiting researcher (Oct - Dec 2019)</li>
                        <li>_7/2019 : 2 papers <sup><a href="#cutmix-regularization-strategy-to-train-strong-classifiers-with">[CutMix]</a> <a href="#photorealistic-style-transfer-via-wavelet-transforms">[WCT2]</a></sup> are accepted at ICCV 2019 (1 oral presentation).</li>
                        <li>_6/2019 : Giving a talk at ICML 2019 Expo workshop.</li>
                        <li>_5/2019 : 2 papers <sup><a href="#visualizing-and-understanding-self-attention-based-music-tagging">[MTSA]</a> <a href="#an-empirical-evaluation-on-robustness-and-uncertainty-of-regular">[RegEval]</a></sup> are accepted at ICML 2019 workshops (1 oral presentation).</li>
                        <li>_5/2019 : Giving a talk at ICLR 2019 Expo talk.</li>
                        <li>_3/2019 : 1 paper <sup><a href="#where-to-be-adversarial-perturbations-added-investigating-and-ma">[PRM]</a></sup> is accepted at ICLR 2019 workshop.</li>
                    </details>
                </div>
                <hr>
                <h3 id="papers">Publications</h3>
                <p>
                    <strong>(C: peer-reviewed conference, W: peer-reviewed workshop, A: arxiv preprint, O: others)<br>
                    <span class="text-danger">(<sup>&#10059;</sup>authors contributed equally)</strong></span><br>
                    See also at my <a href="https://scholar.google.co.kr/citations?user=4_uj0xcAAAAJ">Google Scholar</a>.
                </p>

                <div class="card mb-4">
                    <div class="card-header">
                        <h5 class="float-left mb-0" id="papers-selected">Selected Publications</h5>
                        <div class="clearfix"></div>
                    </div>
                    <ul class="list-group list-group-flush">
                        <li class="list-group-item">
                            <strong>Probabilistic Embeddings for Cross-Modal Retrieval.</strong>
                            <ul>
                                <li><strong>Sanghyuk Chun</strong>, Seong Joon Oh, Rafael Sampaio de Rezende, Yannis Kalantidis, Diane Larlus</li>
                                <li><strong><em>CVPR 2021.</em></strong> <a href="media/papers/chun2021cvpr_pcme.pdf">paper</a> | <a href="https://github.com/naver-ai/pcme">code</a> | <a href="https://www.youtube.com/watch?v=J_DaqSLEcVk">video</a> | <a href="https://docs.google.com/presentation/d/1Tyac3fRvEGYkmbB9iUELU5jjv8IWo5oU_eQUGOkiCuk/edit?usp=sharing">slide (short talk)</a> | <a href="https://docs.google.com/presentation/d/1dGQUqud3iMld-UgMMlRQuqA7JhzndMfzFoKaFAwZ58I/edit?usp=sharing">slide (long talk)</a> | <a href="media/bibtex/chun2021pcme.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item">
                            <strong>AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights.</strong>
                            <ul>
                                <li>Byeongho Heo<sup>&#10059;</sup>, <strong>Sanghyuk Chun</strong><sup>&#10059;</sup>, Seong Joon Oh, Dongyoon Han, Sangdoo Yun, Gyuwan Kim, Youngjung Uh, Jung-Woo Ha</li>
                                <li><strong><em>ICLR 2021.</em></strong> <a href="media/papers/heo2021iclr_adamp.pdf">paper</a> | <a href="https://github.com/ClovaAI/AdamP">code</a> | <a href="https://clovaai.github.io/AdamP/">project page</a> | <a href="https://pypi.org/project/adamp/">pypi</a> | <a href="https://docs.google.com/presentation/d/1s9zgQ22WFnhEj6POL_0ecrTiED__qmL9XgL0Nv3zNP4/edit?usp=sharing">slide</a> | <a href="media/bibtex/heo2021adamp.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item">
                            <strong>Learning De-biased Representations with Biased Representations.</strong>
                            <ul>
                                <li>Hyojin Bahng, <strong>Sanghyuk Chun</strong>, Sangdoo Yun, Jaegul Choo, Seong Joon Oh</li>
                                <li><strong><em>ICML 2020.</em></strong> <a href="media/papers/bahng2020icml_rebias.pdf">paper</a> | <a href="https://github.com/clovaai/rebias">code</a> | <a href="https://twitter.com/SanghyukChun/status/1278357842362155008">tweet</a> | <a href="https://youtu.be/lkjMxZDGubA">video</a> | <a href="https://docs.google.com/presentation/d/1edTv6-gHs-HCF10f2gUCIXiWJ-nSZWg7dzp5q-eKeRk/edit?usp=sharing">slide</a> | <a href="media/bibtex/bahng2020rebias.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item">
                            <strong>SWAD: Domain Generalization by Seeking Flat Minima.</strong>
                            <ul>
                                <li>Junbum Cha, <strong>Sanghyuk Chun</strong><sup>&#10059;</sup>, Kyungjae Lee<sup>&#10059;</sup>, Han-Cheol Cho, Seunghyun Park, Yunsung Lee, Sungrae Park</li>
                                <li><strong><em>NeurIPS 2021.</em></strong> <a href="media/papers/cha2021neurips_swad.pdf">paper</a> | <a href="https://github.com/khanrc/swad">code</a> | <a href="media/bibtex/cha2021neurips_swad.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item">
                            <strong>CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features.</strong>
                            <ul>
                                <li>Sangdoo Yun, Dongyoon Han, Seong Joon Oh, <strong>Sanghyuk Chun</strong>, Junsuk Choe, Youngjoon Yoo</li>
                                <li><strong><em>ICCV 2019.</em></strong> <a href="media/papers/yun2019iccv_cutmix.pdf">paper</a> | <a href="https://github.com/ClovaAI/CutMix-PyTorch">code and pretrained models</a> | <a href="https://clova-ai.blog/2019/07/15/cutmix-regularization-strategy-to-train-strong-classifiers-with-localizable-features/">blog</a> | <a href="media/bibtex/yun2019cutmix.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item">
                            <strong>An Empirical Evaluation on Robustness and Uncertainty of Regularization methods.</strong>
                            <ul>
                                <li><strong>Sanghyuk Chun</strong>, Seong Joon Oh, Sangdoo Yun, Dongyoon Han, Junsuk Choe, Youngjoon Yoo</li>
                                <li><strong><em>ICML Workshop 2019.</em></strong> <a href="media/papers/chun2019icmlws.pdf">paper</a> | <a href="media/bibtex/chun2019icmlw.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item">
                            <strong>Re-labeling ImageNet: from Single to Multi-Labels, from Global to Localized Labels.</strong>
                            <ul>
                                <li>Sangdoo Yun, Seong Joon Oh, Byeongho Heo, Dongyoon Han, Junsuk Choe, <strong>Sanghyuk Chun</strong></li>
                                <li><strong><em>CVPR 2021.</em></strong> <a href="media/papers/yun2021cvpr_relabel.pdf">paper</a> | <a href="https://github.com/naver-ai/relabel_imagenet">code</a> | <a href="media/bibtex/yun2021relabel.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item">
                            <strong>Rethinking Spatial Dimensions of Vision Transformers.</strong>
                            <ul>
                                <li>Byeongho Heo, Sangdoo Yun, Dongyoon Han, <strong>Sanghyuk Chun</strong>, Junsuk Choe, Seong Joon Oh</li>
                                <li><strong><em>ICCV 2021.</em></strong> <a href="media/papers/heo2021iccv_pit.pdf">paper</a> | <a href="https://github.com/naver-ai/pit">code</a> | <a href="https://twitter.com/SanghyukChun/status/1377125468999049216">tweet</a> | <a href="media/bibtex/heo2021pit.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item">
                            <strong>Multiple Heads are Better than One: Few-shot Font Generation with Multiple Localized Experts.</strong>
                            <ul>
                                <li>Song Park, <strong>Sanghyuk Chun</strong>, Junbum Cha, Bado Lee, Hyunjung Shim</li>
                                <li><strong><em>ICCV 2021.</em></strong> <a href="media/papers/park2021iccv_mxfont.pdf">paper</a> | <a href="https://github.com/clovaai/mxfont">code</a> | <a href="media/bibtex/park2021mxfont.txt">bibtex</a></li>
                            </ul>
                        </li>
                    </ul>
                </div>

                <div class="card mb-4">
                    <div class="card-header">
                        <h5 class="float-left mb-0" id="papers-2021">2021</h5>
                        <!--<span class="float-left"><strong> &nbsp; &nbsp; (1 AAAI, 1 ICLR, 2 CVPR, 1 CVPR Workshop, 2 ICCV)</strong></span>-->
                        <div class="clearfix"></div>
                    </div>
                    <ul class="list-group list-group-flush">
                        <li class="list-group-item li-arxiv">
                            <strong class="anchor-strong">ViDT: An Efficient and Effective Fully Transformer-based Object Detector.</strong>
                            <ul>
                                <li>Hwanjun Song, Deqing Sun, <strong>Sanghyuk Chun</strong>, Varun Jampani, Dongyoon Han, Byeongho Heo, Wonjae Kim, Ming-Hsuan Yang</li>
                                <li><strong><em>preprint.</em></strong> <a href="media/papers/song2021vidt.pdf">paper</a> | <a href="https://github.com/naver-ai/vidt">code</a> | <a href="media/bibtex/song2021vidt.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-arxiv">
                            <strong class="anchor-strong">Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective.</strong>
                            <ul>
                                <li>Luca Scimeca<sup>&#10059;</sup>, Seong Joon Oh<sup>&#10059;</sup>, <strong>Sanghyuk Chun</strong>, Michael Poli, Sangdoo Yun</li>
                                <li><strong><em>preprint.</em></strong> <a href="media/papers/scimeca2021wcst-ml.pdf">paper</a> | <a href="media/bibtex/scimeca2021wcst-ml.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">SWAD: Domain Generalization by Seeking Flat Minima.</strong>
                            <ul>
                                <li>Junbum Cha, <strong>Sanghyuk Chun</strong><sup>&#10059;</sup>, Kyungjae Lee<sup>&#10059;</sup>, Han-Cheol Cho, Seunghyun Park, Yunsung Lee, Sungrae Park</li>
                                <li><strong><em>NeurIPS 2021.</em></strong> <a href="media/papers/cha2021neurips_swad.pdf">paper</a> | <a href="https://github.com/khanrc/swad">code</a> | <a href="media/bibtex/cha2021neurips_swad.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Neural Hybrid Automata: Learning Dynamics with Multiple Modes and Stochastic Transitions.</strong>
                            <ul>
                                <li>Michael Poli<sup>&#10059;</sup>, Stefano Massaroli<sup>&#10059;</sup>, Luca Scimeca, Seong Joon Oh, <strong>Sanghyuk Chun</strong>, Atsushi Yamashita, Hajime Asama, Jinkyoo Park, Animesh Garg</li>
                                <li><strong><em>NeurIPS 2021.</em></strong> <a href="media/papers/poli2021nha.pdf">paper</a> | <a href="media/bibtex/poli2021nha.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-arxiv">
                            <strong class="anchor-strong">StyleAugment: Learning Texture De-biased Representations by Style Augmentation without Pre-defined Textures.</strong>
                            <ul>
                                <li><strong>Sanghyuk Chun</strong>, Song Park</li>
                                <li><strong><em>preprint.</em></strong> <a href="media/papers/chun2021styleaugment.pdf">paper</a> | <a href="media/bibtex/chun2021styleaugment.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Rethinking Spatial Dimensions of Vision Transformers.</strong>
                            <ul>
                                <li>Byeongho Heo, Sangdoo Yun, Dongyoon Han, <strong>Sanghyuk Chun</strong>, Junsuk Choe, Seong Joon Oh</li>
                                <li><strong><em>ICCV 2021.</em></strong> <a href="media/papers/heo2021iccv_pit.pdf">paper</a> | <a href="https://github.com/naver-ai/pit">code</a> | <a href="https://twitter.com/SanghyukChun/status/1377125468999049216">tweet</a> | <a href="media/bibtex/heo2021pit.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Multiple Heads are Better than One: Few-shot Font Generation with Multiple Localized Experts.</strong>
                            <ul>
                                <li>Song Park, <strong>Sanghyuk Chun</strong>, Junbum Cha, Bado Lee, Hyunjung Shim</li>
                                <li><strong><em>ICCV 2021.</em></strong> <a href="media/papers/park2021iccv_mxfont.pdf">paper</a> | <a href="https://github.com/clovaai/mxfont">code</a> | <a href="media/bibtex/park2021mxfont.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Probabilistic Embeddings for Cross-Modal Retrieval.</strong>
                            <ul>
                                <li><strong>Sanghyuk Chun</strong>, Seong Joon Oh, Rafael Sampaio de Rezende, Yannis Kalantidis, Diane Larlus</li>
                                <li><strong><em>CVPR 2021.</em></strong> <a href="media/papers/chun2021cvpr_pcme.pdf">paper</a> | <a href="https://github.com/naver-ai/pcme">code</a> | <a href="https://www.youtube.com/watch?v=J_DaqSLEcVk">video</a> | <a href="https://docs.google.com/presentation/d/1Tyac3fRvEGYkmbB9iUELU5jjv8IWo5oU_eQUGOkiCuk/edit?usp=sharing">slide (short talk)</a> | <a href="https://docs.google.com/presentation/d/1dGQUqud3iMld-UgMMlRQuqA7JhzndMfzFoKaFAwZ58I/edit?usp=sharing">slide (long talk)</a> | <a href="media/bibtex/chun2021pcme.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Re-labeling ImageNet: from Single to Multi-Labels, from Global to Localized Labels.</strong>
                            <ul>
                                <li>Sangdoo Yun, Seong Joon Oh, Byeongho Heo, Dongyoon Han, Junsuk Choe, <strong>Sanghyuk Chun</strong></li>
                                <li><strong><em>CVPR 2021.</em></strong> <a href="media/papers/yun2021cvpr_relabel.pdf">paper</a> | <a href="https://github.com/naver-ai/relabel_imagenet">code</a> | <a href="media/bibtex/yun2021relabel.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights.</strong>
                            <ul>
                                <li>Byeongho Heo<sup>&#10059;</sup>, <strong>Sanghyuk Chun</strong><sup>&#10059;</sup>, Seong Joon Oh, Dongyoon Han, Sangdoo Yun, Gyuwan Kim, Youngjung Uh, Jung-Woo Ha</li>
                                <li><strong><em>ICLR 2021.</em></strong> <a href="media/papers/heo2021iclr_adamp.pdf">paper</a> | <a href="https://github.com/ClovaAI/AdamP">code</a> | <a href="https://clovaai.github.io/AdamP/">project page</a> | <a href="https://pypi.org/project/adamp/">pypi</a> | <a href="https://docs.google.com/presentation/d/1s9zgQ22WFnhEj6POL_0ecrTiED__qmL9XgL0Nv3zNP4/edit?usp=sharing">slide</a> | <a href="media/bibtex/heo2021adamp.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <!--<li class="list-group-item li-others">-->
                            <!--<strong class="anchor-strong">Few-shot Font Generation with Weakly Supervised Localized Representations.</strong>-->
                            <!--<ul>-->
                                <!--<li>Song Park<sup>&#10059;</sup>, <strong>Sanghyuk Chun</strong><sup>&#10059;</sup>, Junbum Cha, Bado Lee, Hyunjung Shim</li>-->
                                <!--<li>Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI). (Under review)</li>-->
                            <!--</ul>-->
                        <!--</li>-->

                        <li class="list-group-item li-conference-workshop">
                            <strong class="anchor-strong">Few-shot Font Generation with Localized Style Representations and Factorization.</strong>
                            <ul>
                                <li>Song Park<sup>&#10059;</sup>, <strong>Sanghyuk Chun</strong><sup>&#10059;</sup>, Junbum Cha, Bado Lee, Hyunjung Shim</li>
                                <li><strong><em>AAAI 2021.</em></strong> <strong><em>CVPR Workshop 2021.</em></strong> <a href="media/papers/park2021aaai_lffont.pdf">paper</a> | <a href="https://github.com/clovaai/lffont">code</a> | <a href="https://cvml.yonsei.ac.kr/projects/few-shot-font-generation">project page</a> | <a href="media/bibtex/park2021lffont.txt">bibtex</a></li>
                            </ul>
                        </li>
                    </ul>
                </div>

                <div class="card mb-4">
                    <div class="card-header">
                        <h5 class="float-left mb-0" id="papers-2020">2020</h5>
                        <!--<span class="float-left"><strong> &nbsp; &nbsp; (1 ICASSP, 1 CVPR, 1 ICML, 1 CVPR WS, 1 ECCV)</strong></span>-->
                        <div class="clearfix"></div>
                    </div>
                    <ul class="list-group list-group-flush">
                        <!--<li class="list-group-item li-journal">-->
                        <li class="list-group-item li-arxiv">
                            <strong class="anchor-strong">Evaluation for Weakly Supervised Object Localization: Protocol, Metrics, and Datasets.</strong>
                            <ul>
                                <li>Junsuk Choe<sup>&#10059;</sup>, Seong Joon Oh<sup>&#10059;</sup>, <strong>Sanghyuk Chun</strong>, Seungho Lee, Zeynep Akata, Hyunjung Shim</li>
                                <li>Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI). (Under minor revision)</li>
                                <li><strong><em>preprint.</em></strong> <a href="media/papers/choe2020wsoleval_extension.pdf">paper</a> | <a href="https://github.com/ClovaAI/wsolevaluation">code and dataset</a> | <a href="media/bibtex/choe2020wsoleval_extension.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Few-shot Compositional Font Generation with Dual Memory.</strong>
                            <ul>
                                <li>Junbum Cha, <strong>Sanghyuk Chun</strong>, Gayoung Lee, Bado Lee, Seonghyeon Kim, Hwalsuk Lee</li>
                                <li><strong><em>ECCV 2020.</em></strong> <a href="media/papers/cha2020eccv_dmfont.pdf">paper</a> | <a href="https://github.com/clovaai/dmfont">code</a> | <a href="https://www.youtube.com/watch?v=VMrMJf21XEA">video</a> | <a href="media/bibtex/cha2020dmfont.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Learning De-biased Representations with Biased Representations.</strong>
                            <ul>
                                <li>Hyojin Bahng, <strong>Sanghyuk Chun</strong>, Sangdoo Yun, Jaegul Choo, Seong Joon Oh</li>
                                <li><strong><em>ICML 2020.</em></strong> <a href="media/papers/bahng2020icml_rebias.pdf">paper</a> | <a href="https://github.com/clovaai/rebias">code</a> | <a href="https://twitter.com/SanghyukChun/status/1278357842362155008">tweet</a> | <a href="https://youtu.be/lkjMxZDGubA">video</a> | <a href="https://docs.google.com/presentation/d/1edTv6-gHs-HCF10f2gUCIXiWJ-nSZWg7dzp5q-eKeRk/edit?usp=sharing">slide</a> | <a href="media/bibtex/bahng2020rebias.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-workshop">
                            <strong class="anchor-strong">Toward High-quality Few-shot Font Generation with Dual Memory.</strong> <span class="badge badge-danger">Oral presentation</span> <span class="badge badge-warning">The best paper runner-up award</span>
                            <ul>
                                <li>Junbum Cha, <strong>Sanghyuk Chun</strong>, Gayoung Lee, Bado Lee, Seonghyeon Kim, Hwalsuk Lee</li>
                                <li><strong><em>CVPR Workshop 2020.</em></strong> <a href="media/papers/cha2020cvprws.pdf">paper</a> | <a href="media/bibtex/cha2020cvprw.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Evaluating Weakly Supervised Object Localization Methods Right.</strong>
                            <ul>
                                <li>Junsuk Choe<sup>&#10059;</sup>, Seong Joon Oh<sup>&#10059;</sup>, Seongho Lee, <strong>Sanghyuk Chun</strong>, Zeynep Akata, Hyunjung Shim</li>
                                <li><strong><em>CVPR 2020.</em></strong> <a href="media/papers/choe2020cvpr_wsoleval.pdf">paper</a> | <a href="https://github.com/ClovaAI/wsolevaluation">code and dataset</a> | <a href="https://twitter.com/SanghyukChun/status/1271329234217099264">tweet</a> | <a href="media/slides/CVPR20_slide_evaluating_wsol_methods_right.pdf">slide</a> | <a href="https://www.youtube.com/watch?v=Vy1NcMxUi_Y">video on CVPR</a> | <a href="https://youtu.be/D_dEkeb-fto">video on ECCV tutorial</a> | <a href="media/bibtex/choe2020wsoleval.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Data-driven Harmonic Filters for Audio Representation Learning.</strong>
                            <ul>
                                <li>Minz Won, <strong>Sanghyuk Chun</strong>, Oriol Nieto, Xavier Serra</li>
                                <li><strong><em>ICASSP 2020.</em></strong> <a href="media/papers/won2020icassp_hcnn.pdf">paper</a> | <a href="https://github.com/minzwon/sota-music-tagging-models">code and pretrained models</a> | <a href="https://youtu.be/BXHEYb_Axus">video</a> | <a href="media/bibtex/won2020harmonic.txt">bibtex</a></li>
                            </ul>
                        </li>
                    </ul>
                </div>

                <div class="card mb-4">
                    <div class="card-header">
                        <h5 class="float-left mb-0" id="papers-2019">2019</h5>
                        <!--<span class="float-left"><strong> &nbsp; &nbsp; (2 ICCV, 1 ICLR WS, 2 ICML WS, 1 ISMIR LBD)</strong></span>-->
                        <div class="clearfix"></div>
                    </div>
                    <ul class="list-group list-group-flush">
                        <li class="list-group-item li-arxiv">
                            <strong class="anchor-strong">Neural Approximation of Auto-Regressive Process through Confidence Guided Sampling.</strong>
                            <ul>
                                <li>YoungJoon Yoo, <strong>Sanghyuk Chun</strong>, Sangdoo Yun, Jung-Woo Ha, Jaejun Yoo</li>
                                <li><strong><em>preprint.</em></strong> <a href="media/papers/yoo2019nara.pdf">paper</a> | <a href="media/bibtex/yoo2019nara.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-arxiv">
                            <strong class="anchor-strong">Toward Interpretable Music Tagging with Self-attention.</strong>
                            <ul>
                                <li>Minz Won, <strong>Sanghyuk Chun</strong>, Xavier Serra</li>
                                <li><strong><em>preprint.</em></strong> <a href="media/papers/won2019mtsa.pdf">paper</a> | <a href="https://github.com/minzwon/sota-music-tagging-models">code and pretrained models</a> | <a href="media/bibtex/won2019attention.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features.</strong> <span class="badge badge-danger">Oral presentation</span>
                            <ul>
                                <li>Sangdoo Yun, Dongyoon Han, Seong Joon Oh, <strong>Sanghyuk Chun</strong>, Junsuk Choe, Youngjoon Yoo</li>
                                <li><strong><em>ICCV 2019.</em></strong> <a href="media/papers/yun2019iccv_cutmix.pdf">paper</a> | <a href="https://github.com/ClovaAI/CutMix-PyTorch">code and pretrained models</a> | <a href="https://clova-ai.blog/2019/07/15/cutmix-regularization-strategy-to-train-strong-classifiers-with-localizable-features/">blog</a> | <a href="media/bibtex/yun2019cutmix.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">Photorealistic Style Transfer via Wavelet Transforms.</strong>
                            <ul>
                                <li>Jaejun Yoo<sup>&#10059;</sup>, Youngjung Uh<sup>&#10059;</sup>, <strong>Sanghyuk Chun</strong><sup>&#10059;</sup>, Byungkyu Kang, Jung-Woo Ha</li>
                                <li><strong><em>ICCV 2019.</em></strong> <a href="media/papers/yoo2019iccv_wct2.pdf">paper</a> | <a href="https://github.com/ClovaAI/WCT2">code and model weights</a> | <a href="https://youtu.be/o-AgHt1VA30">video</a> | <a href="https://clova-ai.blog/2019/08/06/photorealistic-style-transfer-via-wavelet-transforms-iccv-2019/">blog</a> | <a href="https://sanghyukchun.github.io/home/media/bibtex/yoo2019wct2.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-workshop">
                            <strong class="anchor-strong">Automatic Music Tagging with Harmonic CNN.</strong>
                            <ul>
                                <li>Minz Won, <strong>Sanghyuk Chun</strong>, Oriol Nieto, Xavier Serra</li>
                                <li><strong><em>ISMIR LBD 2019.</em></strong> <a href="media/papers/won2019ismirlbd.pdf">paper</a> | <a href="https://github.com/minzwon/fast-harmonic-cnn">code</a> | <a href="media/bibtex/won2019lbd.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-workshop">
                            <strong class="anchor-strong">An Empirical Evaluation on Robustness and Uncertainty of Regularization methods.</strong>
                            <ul>
                                <li><strong>Sanghyuk Chun</strong>, Seong Joon Oh, Sangdoo Yun, Dongyoon Han, Junsuk Choe, Youngjoon Yoo</li>
                                <li><strong><em>ICML Workshop 2019.</em></strong> <a href="media/papers/chun2019icmlws.pdf">paper</a> | <a href="media/bibtex/chun2019icmlw.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-workshop">
                            <strong class="anchor-strong">Visualizing and Understanding Self-attention based Music Tagging.</strong> <span class="badge badge-danger">Oral presentation</span>
                            <ul>
                                <li>Minz Won, <strong>Sanghyuk Chun</strong>, Xavier Serra</li>
                                <li><strong><em>ICML Workshop 2019.</em></strong> <a href="media/papers/won2019icmlws.pdf">paper</a> | <a href="https://github.com/minzwon/sota-music-tagging-models">code</a> | <a href="https://slideslive.com/38917230/visualizing-and-understanding-selfattention-based-music-tagging">talk video</a> | <a href="media/bibtex/won2019icmlw.txt">bibtex</a></li>
                            </ul>
                        </li>

                        <li class="list-group-item li-workshop">
                            <strong class="anchor-strong">Where To Be Adversarial Perturbations Added? Investigating and Manipulating Pixel Robustness Using Input Gradients.</strong>
                            <ul>
                                <li>Jisung Hwang<sup>&#10059;</sup>, Younghoon Kim<sup>&#10059;</sup>, <strong>Sanghyuk Chun</strong><sup>&#10059;</sup>, Jaejun Yoo, Ji-Hoon Kim, Dongyoon Han</li>
                                <li><strong><em>ICLR Workshop 2019.</em></strong> <a href="media/papers/hwang2019iclrws.pdf">paper</a> | <a href="media/bibtex/hwang2019prm.txt">bibtex</a></li>
                            </ul>
                        </li>
                    </ul>
                </div>

                <div class="card mb-5">
                    <h5 class="card-header" id="papers-2018">~ 2018</h5>
                    <ul class="list-group list-group-flush">
                        <li class="list-group-item li-arxiv">
                            <strong class="anchor-strong">Multi-Domain Processing via Hybrid Denoising Networks for Speech Enhancement.</strong>
                            <ul>
                                <li>Jang-Hyun Kim<sup>&#10059;</sup>, Jaejun Yoo<sup>&#10059;</sup>, <strong>Sanghyuk Chun</strong>, Adrian Kim, Jung-Woo Ha</li>
                                <li><strong><em>preprint.</em></strong> <a href="media/papers/kim2018mdphd.pdf">paper</a> | <a href="https://mdphdnet.github.io/">project page</a> | <a href="media/bibtex/kim2018mdphd.txt">bibtex</a></li>
                            </ul>
                        </li>
                        <li class="list-group-item li-conference">
                            <strong class="anchor-strong">A Study on Intelligent Personalized Push Notification with User History.</strong>
                            <ul>
                                <li>Hyunjong Lee, Youngin Jo, <strong>Sanghyuk Chun</strong>, Kwangseob Kim</li>
                                <li><strong><em>Big Data 2017.</em></strong> <a href="https://ieeexplore.ieee.org/abstract/document/8258081/">paper</a> | <a href="media/bibtex/lee2017ippn.txt">bibtex</a></li>
                            </ul>
                        </li>
                        <li class="list-group-item li-others">
                            <strong class="anchor-strong">Scalable Iterative Algorithm for Robust Subspace Clustering: Convergence and Initialization.</strong>
                            <ul>
                                <li>Master's Thesis, Korea Advanced Institute of Science and Technology, 2016 (advised by <a href="http://alinlab.kaist.ac.kr/shin.html">Jinwoo Shin</a>) <a href="media/papers/chun2016scsi.pdf">paper</a> | <a href="http://github.com/SanghyukChun/SC_SI">code</a></li>
                            </ul>
                        </li>
                    </ul>
                </div>

                <h3 id="activities">Academic Activities</h3>
                <div class="card mb-4">
                    <h5 class="card-header">Professional Service</h5>
                    <div class="card-body">
                        <ul class="list-unstyled mb-0">
                            <li><strong>Reviewer:</strong>
                                <ul>
                                    <li>CVPR 2020 (<strong class="text-danger">outstanding reviewer</strong>), 2021 (<strong class="text-danger">outstanding reviewer</strong>), 2022</li>
                                    <li>ICCV 2021</li>
                                    <li>WACV 2021</li>
                                    <li>ACCV 2020</li>
                                    <li>NeurIPS 2020, 2021</li>
                                    <li>ICML 2021</li>
                                    <li>ICLR 2021, 2022</li>
                                    <li>AAAI 2021</li>
                                </ul>
                            </li>
                        </ul>
                        <ul class="list-unstyled mb-0">
                            <li><strong>Organizer:</strong>
                                <ul>
                                    <li><strong>[WO1]</strong> NeurIPS 2021 Workshop on <a href="https://sites.google.com/view/imagenet-workshop/home">ImageNet: Past, Present, and Future</a></li>
                                </ul>
                            </li>
                        </ul>
                        <ul class="list-unstyled mb-0">
                            <li><strong>Other services:</strong>
                                <ul>
                                    <li><a href="https://iclr.cc/Conferences/2021/Schedule?showEvent=4408">ICLR 2021 Social: ML in Korea</a>, technical chair and session chair</li>
                                </ul>
                            </li>
                        </ul>
                    </div>
                </div>

                <div class="card mb-4">
                    <h5 class="card-header">Awards</h5>
                    <div class="card-body">
                        <ul class="pl15 mb-0">
                            <li>Outstanding reviewer award, CVPR 2021</li>
                            <li>Outstanding reviewer award, CVPR 2020</li>
                            <li>Best paper runner-up award, AI for Content Creation Workshop at CVPR 2020</li>
                        </ul>
                    </div>
                </div>

                <div class="card mb-4">
                    <h5 id="talks" class="card-header">Talks</h5>
                    <div class="card-body">
                        <ul class="list-unstyled mb-0">
                            <li>"Limits and Challenges in Deep Learning Optimizers", UNIST. <a href="https://docs.google.com/presentation/d/1NNftqS6BcCPd52tv8gWEjB34retYhP0FToOFBd9ewkQ/edit">[slide]</a></li>
                            <li>"Towards better cross-modal learning by Probabilistic embedding and AdamP optimizer", UAB CVC. <a href="http://www.cvc.uab.es/?p=7778">[info]</a> <a href="https://docs.google.com/presentation/d/1dGQUqud3iMld-UgMMlRQuqA7JhzndMfzFoKaFAwZ58I/edit?usp=sharing">[slide]</a></li>
                            <li>"AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights", KSIAM (2021). <a href="https://docs.google.com/presentation/d/1s9zgQ22WFnhEj6POL_0ecrTiED__qmL9XgL0Nv3zNP4/edit?usp=sharing">[slide]</a></li>
                            <li>"Towards Few-shot Font Generation", Seoul University and NAVER (2021). <a href="https://docs.google.com/presentation/d/13WoYS9r9C751s3nZ2yF5WdestRXh3V7LFQDOJyCrt9s/edit?usp=sharing">[slide]</a></li>
                            <li>"Learning De-biased Representations with Biased Representations", NAVER (2020). <a href="https://docs.google.com/presentation/d/1edTv6-gHs-HCF10f2gUCIXiWJ-nSZWg7dzp5q-eKeRk/edit?usp=sharing">[slide]</a></li>
                            <li>"Reliable Machine Learning in NAVER AI", Yonsei University (2020). <a href="https://docs.google.com/presentation/d/1CMeF-AbbKBX-NzzcnEe6YiZjWMdzp3ZknPnD2B9mSoE/edit?usp=sharing">[slide]</a></li>
                            <li>"Toward Reliable Machine Learning", <a href="https://www.omnious.com/">omnious</a> and <a href="https://www.nota.ai/">nota</a> (2020). <a href="https://docs.google.com/presentation/d/1XCALHYzk9p_EjON9qckrylGClWZVBpzrFWzrd3a-qhs/edit?usp=sharing">[slide]</a></li>
                            <li>"Reliable Machine Learning", NAVER CVPR 2020 sponser event. <a href="https://europe.naverlabs.com/naver-interactive-sessions-at-cvpr-2020/">[program]</a> <a href="https://docs.google.com/presentation/d/1bzFN6SZman387_etABgP2iuDBUDNbvBbepGRGDKvf64/edit?usp=sharing">[slide]</a> <a href="https://www.youtube.com/watch?v=Z_e_XWJWeJ8">[video]</a></li>
                            <li>"Neural Architectures for Music Representation Learning", NAVER (2020). <a href="media/slides/2020_May_music_architectures.pdf">[slide]</a></li>
                            <li>"Learning generalizable representations with CutMix and ReBias", NAVER Labs Europe (2019).</li>
                            <li>"An empirical evaluation on the generalizability of regularization methods", <a href="https://europe.naverlabs.com/icml2019-expo-workshop-machine-learning-naver/">ICML 2019 Expo Talk: Recent Work on Machine Learning at NAVER</a>. <a href="media/slides/190609_expotalk.pdf">[slide]</a></li>
                            <li>"Recent works on deep learning robustness in Clova AI", <a href="https://iclr.cc/ExpoConferences/2019/schedule?talk_id=3">ICLR 2019 Expo Talk: Representation Learning to Rich AI Services in NAVER and LINE</a>.</li>
                            <li>"Recommendation system in the real world", <a href="https://deepest.ai/">Deepest</a> Summer School 2018. <a href="media/slides/180825_recsys_summer_school.pdf">[slide]</a></li>
                        </ul>
                    </div>
                </div>

                <h3 id="projects">Industry Experience</h3>

                <div class="card mb-4">
                    <h5 class="card-header" id="experience-in-naver">NAVER AI Research (2018 ~ Now)</h5>
                    <ul class="list-group list-group-flush">
                        <li class="list-group-item">
                            <div class="row m-3">
                                <div class="col-md-2">
                                    <figure class="figure">
                                        <img src="assets/img/project_hangul_event.png" width="100%" alt="Hangul" class="figure-img img-fluid rounded">
                                    </figure>
                                    <figure class="figure">
                                        <img src="assets/img/project_hangul_event2.png" width="100%" alt="Hangul" class="figure-img img-fluid rounded">
                                    </figure>
                                    <figure class="figure">
                                        <img src="assets/img/dmfont-teaser.gif" width="100%" alt="DM-Font teasor" class="figure-img img-fluid rounded">
                                    </figure>
                                </div>
                                <div class="col-md-10">
                                    <strong>Hangul Handwriting Font Generation</strong>
                                    <p>Distributed at 2019 Hangul's day (), <a href="https://clova.ai/handwriting/list.html">[Full font list]</a></p>
                                    <ul class="list-unstyled">
                                        <li>Hangul (Korean alphabet, ) originally consists of only 24 sub-letters (, , , , , , , , , , , , , , , , , , , , , , , ), but by combining them, there exist 11,172 valid characters in Hangul. For example, "" is a combination of , , and , and "" is a combination of , , , , and . It makes generating a new Hangul font be very expensive and time-consuming. Meanwhile, <a href="https://hangeul.naver.com/2014/history">since 2008</a>, Naver has distributed Korean fonts for free (named <a href="https://hangeul.naver.com/2017/nanum">Nanum fonts,  </a>).</li>
                                        <li>In 2019, we developed a technology for fully-personalized Hangul generation only with 152 characters. We opened <a href="https://clova.ai/handwriting">an event page</a> where users can submit their own handwriting. The full generated font list can be found in <a href="https://clova.ai/handwriting/list.html">[this link]</a>. Details for the generation technique used for the service was presented in Deview 2019 <a href="https://deview.kr/2019/schedule/294">[Link]</a>.</li>
                                        <li>This work was also extended to the few-shot generation based on the compositionality. See the papers in AI for Content Creation Workshop (AICCW) at CVPR 2020 (short paper) <a href="media/papers/cha2020cvprws.pdf">[Link]</a>, ECCV 2020 (full paper) <a href="media/papers/cha2020eccv_dmfont.pdf">[Link]</a>, AAAI 2021 <a href="media/papers/park2021aaai_lffont.pdf">[Link]</a>, and ArXiv preprint <a href="media/papers/park2021mxfont.pdf">[Link]</a>.</li>
                                        <li class="text-danger"><strong>[BONUS] You can play with my handwriting <a href="handwriting.html">here</a></strong></li>
                                    </ul>
                                </div>
                            </div>
                        </li>

                        <li class="list-group-item">
                            <div class="row m-3">
                                <div class="col-md-2">
                                    <figure class="figure">
                                        <img src="assets/img/project_sticker_recommendation_example.png" width="100%" alt="example sticker" class="figure-img img-fluid rounded">
                                        <figcaption class="figure-caption">Example emoji from <a href="https://store.line.me">LINE sticker shop</a>.<figcaption>
                                    </figure>
                                </div>
                                <div class="col-md-10">
                                    <strong>Emoji Recommendation (LINE Timeline)</strong>
                                    <p>Deployed in Jan. 2019</p>
                                    <ul class="list-unstyled">
                                        <li><a href="https://linecorp.com/en/">LINE</a> is a major messenger player in east asia (Japan, Taiwan, Thailand, Indonesia, and Korea). In the application, users can buy and use numerous emoijs a.k.a. <a href="https://store.line.me">LINE Sticker</a>.</li>
                                        <li>In this project, we recommended emojis to users based on their profile picture (<strong>cross-domain recommendation</strong>).</li>
                                        <li>I developed and researched the entire pipeline of the cross-domain recommendation system and operation tools.</li>
                                    </ul>
                                </div>
                            </div>
                        </li>
                    </ul>
                </div>

                <div class="card mb-4">
                    <h5 class="card-header" id="experience-in-kakao">Kakao Advanced Recommendation Technology (ART) team (2016 ~ 2018)</h5>
                    <ul class="list-group list-group-flush">
                        <li class="list-group-item">
                            <div class="row m-3">
                                <div class="col-md-2">
                                    <figure class="figure">
                                        <img src="assets/img/project_kakao.png" width="100%" alt="Kakao" class="figure-img img-fluid rounded">
                                    </figure>
                                </div>
                                <div class="col-md-10">
                                    <strong>Recommender Systems (Kakao services)</strong>
                                    <p>Feb. 2016 - Feb. 2018</p>
                                    <ul class="list-unstyled">
                                        <li>I developed and maintained a large-scale real-time recommender system (Toros <a href="https://archive.pycon.kr/2016apac/program/50">[PyCon Talk]</a> <a href="https://brunch.co.kr/@kakao-it/72">[AI Report]</a>) for various services in <a href="https://www.daum.net/">Daum</a> and <a href="https://www.kakaocorp.com/?lang=en">Kakao</a>. I mainly worked with content-based representation modeling (for textual, visual, and musical data), collaborative filtering modeling, user embedding, user clustering, and ranking system based on Multi-armed Bandit.</li>
                                        <li><strong>Textual domain:</strong> <a href="https://media.daum.net/">Daum News</a> similar article recommendation, <a href="https://brunch.co.kr/">Brunch</a> (blog service) similar post recommendation, <a href="http://cafe.daum.net/">Daum Cafe</a> (community service) hit item recommendation.</li>
                                        <li><strong>Visual domain:</strong> <a href="http://webtoon.daum.net/">Daum Webtoon</a> and <a href="https://page.kakao.com/main">Kakao Page</a> similar item recommendation, video recommendation for a news article (cross-domain recommendation).</li>
                                        <li><strong>Audio domain:</strong> music recommendation for <a href="https://kakao.ai/product/kakaomini">Kakao Mini</a> (smart speaker), <a href="http://melon.com/">Melon</a> and <a href="https://www.kakaocorp.com/service/KakaoMusic?lang=en">Kakao Music</a>.</li>
                                        <li><strong>Online to offline:</strong> <a href="https://www.kakaocorp.com/service/KakaoHairShop?lang=en">Kakao Hairshop</a> style recommendation.</li>
                                    </ul>
                                </div>
                            </div>
                        </li>

                        <li class="list-group-item">
                            <div class="row m-3">
                                <div class="col-md-2">
                                    <figure class="figure">
                                        <img src="assets/img/project_ippn.png" width="100%" alt="IPPN" class="figure-img img-fluid rounded">
                                        <figcaption class="figure-caption">System overview.<figcaption>
                                    </figure>
                                </div>
                                <div class="col-md-10">
                                    <strong>Personalized Push Notification with User History (Daum, Kakao Page)</strong>
                                    <p>Deployed in 2017</p>
                                    <ul class="list-unstyled">
                                        <li>The mobile push service (or alert system) is widely-used in mobile applications to attain a high user retention rate. However, a freqeunt push notification makes a user feel fatigue, resulting on the application removal. Usually, the push notification system is a rule-based system, and managed by human labor. In this project, we researched and developed a personalized push notification system based on user activity and interests. The system has been applied to Daum an Kakao Page mobile applications. More details are in <a href="https://ieeexplore.ieee.org/abstract/document/8258081/">our paper</a>.</li>
                                    </ul>
                                </div>
                            </div>
                        </li>

                        <li class="list-group-item">
                            <div class="row m-3">
                                <div class="col-md-2">
                                    <figure class="figure">
                                        <img src="assets/img/project_daumshopping.png" width="100%" alt="Daum Shopping" class="figure-img img-fluid rounded">
                                    </figure>
                                </div>
                                <div class="col-md-10">
                                    <strong>Large-Scale Item Categorization in e-Commerce (Daum Shopping)</strong>
                                    <p>Deployed in 2017</p>
                                    <ul class="list-unstyled">
                                        <li>An accurate categorization helps users to search desired items in e-Commerce based on the category, e.g., clothes / shoes / sneakers. However, the categorization is usually performed based on rule-based systems or human labor, which leads to low coverage of categorized items. Even the automatic item categorization is difficult due to its web-scale data size, the highly unbalanced annotation distribution, and noisy labels. I developed a large-scale item categorization system for <a href="http://shopping.daum.net/">Daum Shopping</a> based on a deep network, from the operation tool to the categorization API.</li>
                                    </ul>
                                </div>
                            </div>
                        </li>
                    </ul>
                </div>

                <div class="card mb-4">
                    <h5 class="card-header" id="experience-in-internship">Internship</h5>
                    <ul class="list-group list-group-flush">
                        <li class="list-group-item">
                            <div class="row m-3">
                                <div class="col-md-2">
                                    <figure class="figure">
                                        <img src="assets/img/project_naverlabs.png" width="100%" alt="Naver Labs" class="figure-img img-fluid rounded">
                                    </figure>
                                </div>
                                <div class="col-md-10">
                                    <strong>Research internship (Naver Labs)</strong>
                                    <p>Aug. 2015 - Dec. 2015</p>
                                    <ul class="list-unstyled">
                                        <li>During the internship, I implemented batch normalization (BN) to AlexNet, Inception v2 and VGG on ImageNet using Caffe. I also researched batch normalization for sequential models, e.g., RNN using Lua Torch.</li>
                                    </ul>
                                </div>
                            </div>
                        </li>

                        <li class="list-group-item">
                            <div class="row m-3">
                                <div class="col-md-2">
                                    <figure class="figure">
                                        <img src="assets/img/project_ium.png" width="100%" alt="IUM-SOCIUS" class="figure-img img-fluid rounded">
                                    </figure>
                                </div>
                                <div class="col-md-10">
                                    <strong>Software engineer (IUM-SOCIUS)</strong>
                                    <p>Jun. 2012 - Jan. 2013</p>
                                    <ul class="list-unstyled">
                                        <li>I worked as web developer at IUM-SOCIUS. During the internship, I developed and maintained internal batch services (JAVA spring batch), internal statistics service (Python Flask, MongoDB), internal admin tools (Python Django, MySQL), and main service systems (JAVA spring, Ruby on Rails, MariaDB).</li>
                                    </ul>
                                </div>
                            </div>
                        </li>
                    </ul>
                </div>

                <h3 id="edu">Education and Career</h3>
                <div class="card mb-4">
                    <div class="card-body">
                        <ul class="list-unstyled mb-0">
                            <li>M.S. (2014.03 - 2016.02), School of Electrical Engineering, KAIST</li>
                            <li>B.S. (2009.03 - 2014.02), School of Electrical Engineering and School of Management Science (double major), KAIST</li>
                        </ul>
                        <hr>
                        <ul class="pl15">
                            <li>Tech leader / research scientist at NAVER AI Lab (Feb. 2018 - Now)</li>
                            <ul class="pl15">
                            <li>Visiting researcher at <a href="https://europe.naverlabs.com/">Naver Labs Europe</a> (Oct. 2019 - Dec. 2019)</li>
                            </ul>
                            <li>Research engineer at advanced recommendation team (ART) in <a href="https://www.kakaocorp.com/">Kakao</a> (Feb. 2016 - Feb. 2018)</li>
                            <li>Research internship at <a href="https://www.naverlabs.com/">Naver Labs</a> (Aug. 2015 - Dec. 2015)</li>
                            <li>Master's degree in Electrical Engineering from KAIST (advisor: <a href="http://alinlab.kaist.ac.kr/shin.html">Jinwoo Shin</a>) (Mar. 2014 - Feb. 2016)</li>
                            <li>Undergraduate researcher at <a href="http://alinlab.kaist.ac.kr/">Algorithmic Intelligence Lab</a> in KAIST (Fall 2013)</li>
                            <li>Undergraduate researcher at <a href="http://www.ndsl.kaist.edu/">Networked and Distributed Computing System Lab</a> in KAIST (Summer 2013)</li>
                            <ul class="pl15">
                            <li>Participated as an undergraduate researcher for <a href="https://www.usenix.org/system/files/conference/atc15/atc15-paper-lee-jihyung.pdf">FloSIS: A Highly Scalable Network Flow Capture System for Fast Retrieval and Storage Efficiency</a> (presented at USENIC ATC 2015) (I developed the index system described in Section 4.)</li>
                            </ul>
                            <li>Software engineering internship at <a href="http://i-um.com/">IUM-SOCIUS</a> (Jun. 2012 - Jan. 2013)</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Optional JavaScript -->
        <!-- jQuery first, then Popper.js, then Bootstrap JS -->
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <script src="assets/js/anchor.min.js"></script>
        <script>
            anchors.add("h2, h3, h4, h5");
            var liAnchors = new AnchorJS({
                placement: 'right',
                icon: ''
            });
            liAnchors.add('.anchor-strong');

            $(".collapse_btn").click(function(){
                $(this).text(function(i, old){
                    if (old == "hide") {
                        return "show more";
                    } else {
                        return "hide";
                    }
                });
            });

            var n_arxiv = $(".li-arxiv").length + 1;
            var n_conf = $(".li-conference").length + $(".li-conference-workshop").length + 1;
            var n_ws = $(".li-workshop").length + $(".li-conference-workshop").length + 1;
            var n_journal = $(".li-journal").length + 1;
            $("head").append("<style>body {counter-reset: arxivcounter " + n_arxiv + " confcounter " + n_conf + " wscounter " + n_ws + " journalcounter " + n_journal + "; padding-left: 0;}</style>")
        </script>
    </body>
</html>
